{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use the DefaultTagger! Write a code to tag the simple phrase \"Hello World\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hello', 'NN'), ('World', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "s = \"Hello World\"\n",
    "words = s.split()\n",
    "\n",
    "from nltk.tag import DefaultTagger\n",
    "tagger = DefaultTagger('NN')\n",
    "print(tagger.tag(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a unigram or n-gram tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a code to train a unigram tagger using the first (already-tagged) 3000 sentences from the 'treebank' corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n",
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import UnigramTagger\n",
    "from nltk.corpus import treebank\n",
    "train_sents = treebank.tagged_sents()[:3000]\n",
    "\n",
    "## Here you can also use 'cutoff' as a second argument to set a\n",
    "## minimum frequency threshold.\n",
    "tagger = UnigramTagger(train_sents)\n",
    "\n",
    "## The untagged words\n",
    "print(treebank.sents()[0])\n",
    "\n",
    "## The tagged words, using a tagger after being trained.\n",
    "print(tagger.tag(treebank.sents()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapt the above code using the BigramTagger and TrigramTagger in the backoff chain to gain some accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8812432549104252"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import UnigramTagger, BigramTagger, TrigramTagger, DefaultTagger\n",
    "from nltk.corpus import treebank\n",
    "train_sents = treebank.tagged_sents()[:3000]\n",
    "test_sents = treebank.tagged_sents()[3000:]\n",
    "\n",
    "from tag_util import backoff_tagger\n",
    "backoff = DefaultTagger('NN')\n",
    "tagger = backoff_tagger(train_sents, [UnigramTagger, BigramTagger, TrigramTagger], backoff=backoff)\n",
    "tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a model of likely word tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the 200 most frequent words in 'treebank' as keys, write a code that will use the most frequent tag for each word to create a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8812432549104252"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## For reference, here's the code for word_tag_mode1... take a look!\n",
    "## Note the \"limit=200\" default argument in the function.\n",
    "## \n",
    "## from nltk.probability import FreqDist, ConditionalFreqDist\n",
    "## def word_tag_model(words, tagged_words, limit = 200):\n",
    "##     fd = FreqDist(words)\n",
    "##     cfd = ConditionalFreqDist(tagged_words)\n",
    "##     most_freq = (word for word, count in fd.most_common(limit))\n",
    "##     return dict((word, cfd[word].max()) for word in most_freq)\n",
    "\n",
    "## Here's the actual code when using UnigramTagger in your backoff chain.\n",
    "\n",
    "from tag_util import word_tag_model\n",
    "from nltk.tag import UnigramTagger, BigramTagger, TrigramTagger\n",
    "from nltk.corpus import treebank\n",
    "train_sents = treebank.tagged_sents()[:3000]\n",
    "test_sents = treebank.tagged_sents()[3000:]\n",
    "\n",
    "model = word_tag_model(treebank.words(), treebank.tagged_words())\n",
    "default_tagger = DefaultTagger('NN')\n",
    "likely_tagger = UnigramTagger(model = model, backoff=default_tagger)\n",
    "tagger =  backoff_tagger(train_sents, [UnigramTagger, BigramTagger, TrigramTagger], backoff=likely_tagger)\n",
    "\n",
    "tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tagging with regular expressions, affix tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After reading up on the RegexpTagger, write a code using the AffixTagger that trains it on three-character prefixes.\n",
    "\n",
    "### How do you think the AffixTagger works relative to the RegexpTagger?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.236088927260954"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import AffixTagger\n",
    "from nltk.corpus import treebank\n",
    "train_sents = treebank.tagged_sents()[:3000]\n",
    "test_sents = treebank.tagged_sents()[3000:]\n",
    "\n",
    "prefix_tagger = AffixTagger(train_sents, affix_length=3)\n",
    "prefix_tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Brill tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Brill tagger using a backoff chain using NgramTagger classes (pass them into the train_brill_tagger())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8834016835743579"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import DefaultTagger\n",
    "from nltk.tag import UnigramTagger, BigramTagger, TrigramTagger\n",
    "\n",
    "from nltk.corpus import treebank\n",
    "train_sents = treebank.tagged_sents()[:250]\n",
    "test_sents = treebank.tagged_sents()[250:1000]\n",
    "## Here we used fewer words than in the book. \n",
    "# Otherwise the training/proccessing takes a very long time.\n",
    "\n",
    "from tag_util import backoff_tagger\n",
    "\n",
    "default_tagger = DefaultTagger('NN')\n",
    "initial_tagger = backoff_tagger(train_sents, [UnigramTagger, BigramTagger, TrigramTagger], \n",
    "                                backoff=default_tagger)\n",
    "## print(initial_tagger.evaluate(test_sents))\n",
    "\n",
    "from tag_util import train_brill_tagger\n",
    "\n",
    "brill_tagger = train_brill_tagger(initial_tagger, train_sents)\n",
    "brill_tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the TnT tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a code to train the TnT tagger on the training sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8757176775307576\n"
     ]
    }
   ],
   "source": [
    "## Old imports\n",
    "from nltk.corpus import treebank\n",
    "train_sents = treebank.tagged_sents()[:250]\n",
    "test_sents = treebank.tagged_sents()[250:1000]\n",
    "## Here we used fewer words than in the book. \n",
    "# Otherwise the training/proccessing takes a very long time.\n",
    "\n",
    "from nltk.tag import tnt\n",
    "\n",
    "tnt_tagger = tnt.TnT()\n",
    "tnt_tagger.train(train_sents)\n",
    "tnt_tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using WordNet for tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a code that uses Wordnet tagger as part of a backoff chain and check its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7569835369091875"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import treebank\n",
    "from nltk.tag import UnigramTagger, BigramTagger, TrigramTagger\n",
    "train_sents = treebank.tagged_sents()[:250]\n",
    "test_sents = treebank.tagged_sents()[250:1000]\n",
    "## Here we used fewer words than in the book. \n",
    "# Otherwise the training/proccessing takes a very long time.\n",
    "\n",
    "# Save taggers.py to your folder where you're doing work.\n",
    "from taggers import WordNetTagger\n",
    "wn_tagger = WordNetTagger()\n",
    "\n",
    "tagger = backoff_tagger(train_sents, [UnigramTagger,BigramTagger,TrigramTagger], backoff=wn_tagger)\n",
    "tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tagging proper names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a code that uses the NameTagger from taggers.py. Think about where you would use this in a backoff chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Jacob', 'NNP')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from taggers import NamesTagger\n",
    "nt = NamesTagger()\n",
    "nt.tag(['Jacob'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifer-based tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a code to train the classifier based tagger on the training sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9309734513274336"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Old imports...\n",
    "from nltk.corpus import treebank\n",
    "train_sents = treebank.tagged_sents()[:3000]\n",
    "test_sents = treebank.tagged_sents()[3000:]\n",
    "\n",
    "from nltk.tag.sequential import ClassifierBasedPOSTagger\n",
    "tagger = ClassifierBasedPOSTagger(train=train_sents)\n",
    "tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a tagger with NLTK-Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read about command-line NLTK-Trainer (https://github.com/japerk/nltk-trainer) and get some practice in.\n",
    "\n",
    "### Train a classifier based tagger with the treebank corpus."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
